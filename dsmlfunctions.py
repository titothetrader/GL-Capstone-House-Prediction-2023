# -*- coding: utf-8 -*-
"""DSMLfunctions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11zDgj-KW_TQ1wRNf3bIE5OhE1tkmUJAT

# DSML Global Functions 01 - Data Details (info, describe, columns, etc.)
"""

# Commented out IPython magic to ensure Python compatibility.
# Used to ignore the warning given as output of the code
import warnings                                 
# warnings.filterwarnings('ignore')

# import the important packages
import numpy as np               # NumPy is used for arrays
import pandas as pd              # Pandas is used for data manipulation, especially through DataFrames
import re                        # Regulat expressions for date format
from datetime import datetime    # Date string manipulation
from IPython.display import display # Display dataframes nicely
import matplotlib.pyplot as plt  # Matplotlib's PyPlot is used for plots and visualizations
import seaborn as sns            # SeaBorn is for advanced graphs or better style
sns.set_style('darkgrid')

# Magic Function that displays results inline after code block
# %matplotlib inline               

from sklearn.cluster import KMeans                  # KMeans clustering
from sklearn.linear_model import LinearRegression   # Linear Regression Model

# Multicollinearity using VIF
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Get Metrics to evlauate models: MAE, MAPE, MSE, R2
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error, r2_score 

import scipy.stats as stats      # SciPy Stats contains probability distributions and statistical functions

# Progress bar for loops
#for item in progress_bar(my_list):
#    process(item)
from fastprogress import master_bar, progress_bar

# Import the dataset
data = pd.read_csv('/content/drive/MyDrive/DSML/GL-Capstone-Houses-03-2023/Dataset+-+House+Price+Prediction+-+innercity.xlsx+-+innercity.csv')

def getGeneralInfo(data):
  print('')
  print('===============')
  print('Data Head')
  print('===============')
  display(data.head(5))

  print('')
  print('===============')
  print('Data Shape')
  print('===============')
  print(data.shape)

  print('')
  print('===============')
  print('Data Info')
  print('===============')
  print(data.info())

  print('')
  print('===============')
  print('Number Columns')
  print('===============')
  num_cols = data.select_dtypes(include=["number"])
  display(num_cols.head(5))
  print(num_cols.shape)

  print('')
  print('===============')
  print('Object Columns')
  print('===============')
  obj_cols = data.select_dtypes(exclude=["number"])
  display(obj_cols.head(5))
  print(obj_cols.shape)

def getDataDescribe(data):
  print('')
  print('===============')
  print('Data Describe')
  print('===============')
  display(data.describe().T.apply(lambda s: s.apply('{0:.5f}'.format)))

"""# DSML Global Functions 02 - Null Handling"""

def getNullHandler(data):
  print('')
  print('===============')
  print('Data Null Handler')
  print('===============')
  print('Nulls present:',data.isnull().values.any())
  print('Nulls count:',data.isnull().sum().sum())
  print(data.isnull().sum())
  print('---------------')
  print('Imputing Object columns with most frequent (mode) and Number columns with middle value (median)')
  # Imputing missing values with mode (most frequent) for Object columns and with median for all other columns
  for col in data.columns:
      if data[col].dtype == "object":
          data[col].fillna(value=data[col].mode()[0], inplace=True)
      elif data[col].dtype == "int64" or data[col].dtype =="float64":
          data[col].fillna(value=data[col].median(), inplace=True)
      # return data
  print('---------------')
  print('Confirming no nulls left')
  print('Nulls present:',data.isnull().values.any())
  print('Nulls count:',data.isnull().sum().sum())
  return data

"""# DSML Global Functions 03 - Data Cleanup

## Date Formats
"""

def getDateHandler(data, date_column, current_format):
  dates = data[date_column].apply(lambda d: datetime.strptime(d, current_format))
  # Create dummy columns
  data['year'] = [d.year for d in dates]
  data['month'] = [d.month for d in dates]
  data['day'] = [d.day for d in dates]
  # drop the date column
  data = data.drop(columns=[date_column])

  display(data.head(5))
  return data, dates

"""## Remove Rows Where Column Has Specific Value"""

def getRemoveRowsWithValue(data, columnList, value):
  print('')
  print('===============')
  print(f'Removing "{value}" from columns')
  print('===============')
  for column in columnList:
    print('')
    print(f'--- Removing "{value}" from "{column}" ---')
    data.drop(data[data[column] == value].index, inplace = True)
    print(data[column].value_counts())
  return data

"""### Convert Object Column to Number"""

def getConvertObjectToNumber(data, columnList):
  print('')
  print('===============')
  print(f'Converting Columns to Number')
  print('===============')
  for column in columnList:
    print('')
    data[column] = pd.to_numeric(data[column])
    print(f'--- Converted "{column}" to {data[column].dtypes} ---')
  return data

"""### Handling Outliers"""

def getOutliersHandler(data, excluded_columns, factor = 1.5):
  num_cols = data.select_dtypes(include=["number"])
  data_outliers_fixed = data.copy()
  
  k = len(num_cols.columns)
  n = 4
  m = (k - 1) // n + 1
  print('')
  print('===============')
  print(f'Removing Outliers with IQR factor of: {factor}')
  print('===============')
  for col in num_cols:
    if col in excluded_columns:
      continue
    else:
      # r, c = i // n, i % n
      q1 = data_outliers_fixed[col].quantile(.25)
      q3 = data_outliers_fixed[col].quantile(.75)
      iqr = q3 - q1
      upper_whisker = q3 + (factor * iqr)
      lower_whisker = q1 - (factor * iqr)
      data_outliers_fixed[col] = np.where(data_outliers_fixed[col] > upper_whisker, upper_whisker, np.where(data_outliers_fixed[col] < lower_whisker, lower_whisker, data_outliers_fixed[col]))
    
      plt.figure(figsize=(n * 5, m))
      plt.subplot(141)
      sns.histplot(data[col],  stat='density', label="skew: " + str(np.round(data[col].skew(), 2)))
      sns.kdeplot(data[col], color='red', warn_singular=False)
      plt.title('Before', fontsize=20)
      plt.legend()

      plt.subplot(142)
      ax = sns.histplot(data_outliers_fixed[col],  stat='density', label="skew: " + str(np.round(data_outliers_fixed[col].skew(), 2)))
      sns.kdeplot(data_outliers_fixed[col], color='red', warn_singular=False)
      plt.title('After', fontsize=20)
      plt.legend()

      plt.subplot(143)
      sns.boxplot(data[col])
      plt.title('Before', fontsize=20)

      plt.subplot(144)
      sns.boxplot(data_outliers_fixed[col])
      plt.title('After', fontsize=20)

      plt.tight_layout()
      plt.show()
  return data_outliers_fixed

"""# DSML Global Functions 04 - Data Graphs (Histograms & Heat Map)

## Univariate Graphs
"""

def getGeneralHistograms(data):
  num_cols = data.select_dtypes(include=["number"])
  k = len(num_cols.columns)
  n = 4
  m = (k - 1) // n + 1
  fig, axes = plt.subplots(m, n, figsize=(n * 5, m * 3))
  print('')
  print('===============')
  print('Data Numerical Histograms')
  print('===============')
  for i, (name, col) in enumerate(num_cols.iteritems()):
      r, c = i // n, i % n
      ax = axes[r, c]
      col.hist(ax=ax)
      ax2 = col.plot.kde(ax=ax, secondary_y=True, title=name, color='red')
      ax2.set_ylim(0)
  fig.tight_layout()
  # plt.title("Histograms", fontsize=20)
  plt.show()

def getGeneralBoxPlots(data):
  num_cols = data.select_dtypes(include=["number"])
  k = len(num_cols.columns)
  n = 4
  m = (k - 1) // n + 1
  fig, axes = plt.subplots(m, n, figsize=(n * 5, m * 3))
  print('')
  print('===============')
  print('Data Numerical Box Plots')
  print('===============')
  for i, col in enumerate(num_cols):
    r, c = i // n, i % n
    sns.boxplot(x = data[col], ax=axes[r, c])
  fig.tight_layout()
  # plt.title("Box Plots", fontsize=20)
  plt.show()

def getGeneralBoxPlotSkew(data):
  num_cols = data.select_dtypes(include=["number"])
  k = len(num_cols.columns)
  n = 4
  m = (k - 1) // n + 1
  print('')
  print('===============')
  print('Box Plots and Skew')
  print('===============')
  for i, col in enumerate(num_cols):
    fig = plt.figure(figsize=(n * 5, m))
    plt.subplot(131)
    ax = sns.histplot(data[col], kde=True, label="skew: " + str(np.round(data[col].skew(), 2)))
    ax.lines[0].set_color('red')
    plt.legend()
    plt.subplot(132)
    sns.boxplot(data[col])
    plt.subplot(133)
    stats.probplot(data[col], plot=plt)
    fig.tight_layout()
    # plt.title("Box Plot Skewness", fontsize=20)
    plt.show()

"""## Bivariate Graphs"""

def getGeneralPairplot(data, target_column):
  sns.pairplot(data, hue=target_column)
  plt.title(f"Pair Plot vs {target_column}", fontsize=20)
  plt.show()

def getGeneralGraphRegression(data, target_column):
  num_cols = data.select_dtypes(include=["number"])
  k = len(num_cols.columns)
  n = 4
  m = (k - 1) // n + 1
  fig = plt.subplots(figsize=(n * 5, m * 3))
  print('')
  print('===============')
  print(f'Data Numerical Scatter Plot with Regression for column: {target_column}')
  print('===============')
  Y = num_cols[target_column].values.reshape(-1, 1)  # df.iloc[:, 4] is the column of Y
  for i, (name, col) in enumerate(num_cols.iteritems()):
    r, c = i // n, i % n
    X = num_cols.iloc[:, i].values.reshape(-1, 1)  # iloc[:, 1] is the column of X
    linear_regressor = LinearRegression()
    linear_regressor.fit(X, Y)
    Y_pred = linear_regressor.predict(X)

    plt.subplot(m, n, i+1)
    plt.scatter(X, Y)
    plt.plot(X, Y_pred, color='red')
    plt.title(name)
  plt.show()

def getGeneralHeatMap(data, show_values = True):
  print('')
  print('===============')
  print('Data Heat Map')
  print('===============')
  num_cols = data.select_dtypes(include=["number"])
  corr=data.corr()

  # Mask to remove upper triangle
  mask = np.triu(np.ones_like(corr, dtype=bool))

  fig, ax = plt.subplots(figsize=(20,20))
  # cmap = sns.diverging_palette(230, 20, as_cmap = True) # red colors

  sns.heatmap(corr, annot = show_values, fmt = '.2f', cmap = 'mako', linewidths=1, mask=mask, vmax=.3, center=0, square=True, cbar_kws={"shrink": .5})
  plt.title("Heat Map", fontsize=20)
  plt.show()

"""# DSML Global Functions 05 - Clustering

## KMeans (number columns only)
"""

# Output number of clusters

def getKMeansCurve(data, max_k):
  print('')
  print('===============')
  print('K-Means Curve')
  print('===============')
  num_cols = data.select_dtypes(include=["number"])
  means = []
  inertias = []

  for k in range(1, max_k):
    kmeans = KMeans(n_clusters=k, n_init=1)
    kmeans.fit(num_cols)

    means.append(k)
    inertias.append(kmeans.inertia_)

  # Generate the elbow plot
  fig = plt.subplots(figsize=(10,5))
  plt.plot(means, inertias, 'o-')
  plt.xlabel('Number of clusters')
  plt.ylabel('Inertia')
  plt.grid(True)
  plt.title(f"KMeans Elbow Curve", fontsize=20)
  plt.show()

# Apply KMeans

def getKMeansLabels(data, k):
  print('')
  print('===============')
  print('K-Means Labels')
  print('===============')
  num_cols = data.select_dtypes(include=["number"])

  kmeans = KMeans(n_clusters=k, n_init=1)
  kmeans.fit(num_cols)

  data["k_means_labels"] = kmeans.labels_

  return data

# Plot KMeans in Scatter Plot of X, Y

def getGroupedScatterPlot(data, x_col, y_col, labels_col):
  print('')
  print('===============')
  print('Grouped Scatter Plot')
  print('===============')
  num_cols = data.select_dtypes(include=["number"])

  sns.lmplot(x=x_col, y=y_col, data=num_cols, hue=labels_col, fit_reg=False, legend=False, height=15, aspect=1)
  
  # Move the legend to an empty part of the plot
  plt.legend(loc='lower right')
  plt.title(f"{x_col} vs {y_col} grouped by: {labels_col}", fontsize=20)
  plt.show()

"""# DSML Global Functions 06 - Multicollinearity"""

#Use this on X_train data with a default correlation threshold of abs(0.7)

def getMulticollHandler(data, threshold = 0.7):
  print('')
  print('===============')
  print(f'Multicollinearity Threshold: {threshold}')
  print('===============')
  correlated_cols = set() # get unique elements only
  corr_matrix = data.corr()
  for i in range(len(corr_matrix.columns)):
    for j in range(i):
      if abs(corr_matrix.iloc[i,j]) > threshold:
        colname = corr_matrix.columns[i]
        correlated_cols.add(colname)

  display(correlated_cols)
  
  return correlated_cols

"""## View VIF of X_train or X_test

General Rule of thumb: If VIF is 1 then there is no correlation between the kth predictor and the remaining predictor variables, and  hence the variance of β̂k is not inflated at all. Whereas if **VIF exceeds 5 or is close to exceeding 5, we say there is moderate VIF and if it is 10 or exceeding 10, it shows signs of high multi-collinearity.**
"""

# Function to check VIF
def getVIF(data):
  print('')
  print('===============')
  print('VIF')
  print('===============')
  vif = pd.DataFrame()
  vif["feature"] = data.columns

  # Calculating VIF for each feature
  vif["VIF"] = [
      variance_inflation_factor(data.values, i) for i in range(len(data.columns))
  ]
  # print(vif.loc[vif['VIF'].isnull()], 'feature')
  # print(vif.loc[vif['VIF'] > 10], 'feature')
  
  print(vif)
  return vif

"""# DSML Global Functions 0X - Model Comparison Table
## SciKit Metrics MAE, MAPE, RMSE, RSQUARE
"""

# Receive a Comparison Table to add the calculated metrics
def getModelComparisonMetrics(model_comparison_table, model_number, model_title, y_train, y_test, y_pred_train, y_pred_test):
  print('')
  print('===============')
  print(f'Model Comparison v{model_number}')
  print('===============')

  # Getting MAE
  mae_train = mean_absolute_error(y_train, y_pred_train)
  mae_test = mean_absolute_error(y_test, y_pred_test)

  # Getting MAPE
  mape_train = mean_absolute_percentage_error(y_train, y_pred_train) * 100
  mape_test = mean_absolute_percentage_error(y_test, y_pred_test) * 100

  # Getting RMSE
  RMSE_train = mean_squared_error(y_train, y_pred_train)
  RMSE_test = mean_squared_error(y_test, y_pred_test)

  # Getting R-Square
  RSquare_train = r2_score(y_train, y_pred_train)
  RSquare_test = r2_score(y_test, y_pred_test)
  
  base_results_train = pd.DataFrame({'MAE': mae_train, 'MAPE':mape_train, 'RMSE':RMSE_train, 'RSquare':RSquare_train}, index=[f'Model {model_number} Train: {model_title}'])
  base_results_test = pd.DataFrame({'MAE': mae_test, 'MAPE':mape_test, 'RMSE':RMSE_test, 'RSquare':RSquare_test}, index=[f'Model {model_number} Test: {model_title}'])

  model_comparison_table = model_comparison_table.append(base_results_train)
  model_comparison_table = model_comparison_table.append(base_results_test)

  display(model_comparison_table)
  
  return model_comparison_table

"""# Testing the functions"""

# Testing the Functions

# --- INFO
# getGeneralInfo(data)
# getDataDescribe(data)

# --- CLEANUP
# getDateHandler(data, 'dayhours', '%Y%m%dT000000')

# data = getNullHandler(data)

# columnList = ['ceil', 'coast', 'condition', 'yr_built', 'long', 'total_area']   # List of columns that are of Object type
# data = getRemoveRowsWithValue(data, columnList, '$')
# data = getConvertObjectToNumber(data, columnList)

# --- UNIVARIATE GRAPHS
# getGeneralHistograms(data)
# getGeneralBoxPlots(data)

# --- BIVARIATE GRAPHS
# getGeneralPairplot(data, 'price')
# getGeneralGraphRegression(data, 'price')  # Regression compares against TARGET column
# getGeneralHeatMap(data, True)

# getGeneralBoxPlotSkew(data)

# --- OUTLIERS


# Removing columns that are of Number type but are either 1/0, categorical, date or location
# excluded_columns = ['furnished', 'coast', 'sight', 'condition', 'quality', 'yr_built', 'yr_renovated', 'lat', 'long', 'zipcode']
# data = getOutliersHandler(data, excluded_columns)
# data.describe().T

# --- CLUSTERING

# getKMeansCurve(data, 10)

# data = getKMeansLabels(data, 3)
# data.head()

# getGroupedScatterPlot(data, 'long', 'lat', 'k_means_labels')

# --- Multicollinearity
# Need to remove nulls before

# correlated_columns = getMulticollHandler(data, .7)

